"""
Airbus Ship Detection (Kaggle):
  - HRNetV2 (timm hrnet_w32 / hrnet_w18 など) を features_only として利用
  - Multi-scale feature fusion + simple segmentation head (1 class: ship vs background)
  - Full dataset training on prepared_splits (SCALE_100PCT...)
  - Local evaluation on split val/test (instance-level mean F2 over IoU thresholds + pixel metrics)
  - Kaggle official test image inference -> submission CSV (RLE, multiple rows per image)
  - Logging, checkpoints, best weight saving, resume
"""
import os
import sys
import json
import time
import glob
import argparse
import logging
import datetime
import random
from dataclasses import dataclass
from typing import List, Tuple, Dict, Optional

import numpy as np
from PIL import Image

import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.utils.data import Dataset, DataLoader

try:
    import timm
except ImportError:
    print("[ERROR] timm が見つかりません。`pip install timm` を実行してください。", file=sys.stderr)
    raise

# AMP: torch.amp が推奨。古いtorchでも動くようにフォールバック。
try:
    from torch.amp import autocast as amp_autocast
    from torch.amp import GradScaler as AmpGradScaler
    AMP_NEW = True
except Exception:
    from torch.cuda.amp import autocast as amp_autocast
    from torch.cuda.amp import GradScaler as AmpGradScaler
    AMP_NEW = False

def now_str():
    return datetime.datetime.now().strftime("%Y%m%d_%H%M%S")

def ensure_dir(p: str):
    os.makedirs(p, exist_ok=True)

def set_seed(seed: int, deterministic: bool = False):
    random.seed(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)
    torch.cuda.manual_seed_all(seed)
    if deterministic:
        torch.backends.cudnn.deterministic = True
        torch.backends.cudnn.benchmark = False
    else:
        torch.backends.cudnn.deterministic = False
        torch.backends.cudnn.benchmark = True

def setup_logger(log_path: str) -> logging.Logger:
    logger = logging.getLogger("ship_hrnetv2")
    logger.setLevel(logging.INFO)
    logger.handlers.clear()

    fmt = logging.Formatter("%(asctime)s [%(levelname)s] %(message)s")

    ch = logging.StreamHandler(sys.stdout)
    ch.setLevel(logging.INFO)
    ch.setFormatter(fmt)
    logger.addHandler(ch)

    ensure_dir(os.path.dirname(log_path))
    fh = logging.FileHandler(log_path)
    fh.setLevel(logging.INFO)
    fh.setFormatter(fmt)
    logger.addHandler(fh)

    return logger

def save_json(path: str, obj: dict):
    ensure_dir(os.path.dirname(path))
    with open(path, "w", encoding="utf-8") as f:
        json.dump(obj, f, ensure_ascii=False, indent=2)

def list_images(folder: str, exts=(".jpg", ".jpeg", ".png", ".tif", ".tiff")) -> List[str]:
    files = []
    for e in exts:
        files.extend(glob.glob(os.path.join(folder, f"*{e}")))
    files = sorted(files)
    return files


def rle_encode(mask: np.ndarray) -> str:
    """
    mask: (H,W) {0,1} uint8
    returns: RLE string
    """
    if mask.ndim != 2:
        raise ValueError("mask must be 2D")

    pixels = mask.T.flatten()  # Fortran-like
    pixels = np.concatenate([[0], pixels, [0]])
    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1
    runs[1::2] = runs[1::2] - runs[0::2]
    return " ".join(str(x) for x in runs)

def rle_decode(rle: str, shape: Tuple[int, int]) -> np.ndarray:
    """
    rle: "start length start length ..."
    shape: (H,W)
    returns: (H,W) {0,1} uint8
    """
    h, w = shape
    mask = np.zeros(h * w, dtype=np.uint8)
    if rle is None or rle == "" or (isinstance(rle, float) and np.isnan(rle)):
        return mask.reshape((w, h)).T

    s = list(map(int, rle.split()))
    starts = s[0::2]
    lengths = s[1::2]
    for st, le in zip(starts, lengths):
        st -= 1
        mask[st:st + le] = 1
    return mask.reshape((w, h)).T


# ---------------------------
# Connected Components (instances)
# ---------------------------

def _label_connected_components(binary_mask: np.ndarray) -> Tuple[np.ndarray, int]:
    """
    Returns labeled mask (H,W) with labels 0..N, and N (#components).
    Try OpenCV first, else skimage.
    """
    if binary_mask.dtype != np.uint8:
        binary_mask = binary_mask.astype(np.uint8)

    try:
        import cv2
        num_labels, labels = cv2.connectedComponents(binary_mask, connectivity=8)
        return labels.astype(np.int32), (num_labels - 1)
    except Exception:
        pass

    try:
        from skimage.measure import label as sk_label
        labels = sk_label(binary_mask, connectivity=2)
        n = int(labels.max())
        return labels.astype(np.int32), n
    except Exception as e:
        raise RuntimeError(
            "connected components に cv2 / skimage が必要です。"
            "無い場合は `pip install opencv-python scikit-image`"
        ) from e

def mask_to_instances(binary_mask: np.ndarray, min_area: int = 0) -> List[np.ndarray]:
    labels, n = _label_connected_components(binary_mask.astype(np.uint8))
    insts = []
    for k in range(1, n + 1):
        m = (labels == k).astype(np.uint8)
        if min_area > 0 and m.sum() < min_area:
            continue
        insts.append(m)
    return insts

def iou(a: np.ndarray, b: np.ndarray) -> float:
    inter = float(np.logical_and(a, b).sum())
    union = float(np.logical_or(a, b).sum())
    if union <= 0:
        return 0.0
    return inter / union

def iou_matrix(gt_insts: List[np.ndarray], pr_insts: List[np.ndarray]) -> np.ndarray:
    if len(gt_insts) == 0 or len(pr_insts) == 0:
        return np.zeros((len(gt_insts), len(pr_insts)), dtype=np.float32)
    mat = np.zeros((len(gt_insts), len(pr_insts)), dtype=np.float32)
    for i in range(len(gt_insts)):
        for j in range(len(pr_insts)):
            mat[i, j] = iou(gt_insts[i], pr_insts[j])
    return mat

def match_tp_fp_fn(iou_mat: np.ndarray, thr: float) -> Tuple[int, int, int]:
    G, P = iou_mat.shape
    if G == 0 and P == 0:
        return 0, 0, 0
    if G == 0:
        return 0, P, 0
    if P == 0:
        return 0, 0, G

    pairs = []
    for i in range(G):
        for j in range(P):
            if iou_mat[i, j] >= thr:
                pairs.append((iou_mat[i, j], i, j))
    pairs.sort(reverse=True, key=lambda x: x[0])

    matched_g = set()
    matched_p = set()
    tp = 0
    for _, i, j in pairs:
        if i in matched_g or j in matched_p:
            continue
        matched_g.add(i)
        matched_p.add(j)
        tp += 1

    fp = P - tp
    fn = G - tp
    return tp, fp, fn

def fbeta(precision: float, recall: float, beta: float = 2.0) -> float:
    b2 = beta * beta
    denom = (b2 * precision + recall)
    if denom <= 0:
        return 0.0
    return (1 + b2) * precision * recall / denom

def kaggle_mean_f2_for_image(gt_mask_bin: np.ndarray,
                             pr_mask_bin: np.ndarray,
                             iou_thrs: List[float],
                             min_area: int = 0) -> float:
    gt_insts = mask_to_instances(gt_mask_bin, min_area=0)
    pr_insts = mask_to_instances(pr_mask_bin, min_area=min_area)

    mat = iou_matrix(gt_insts, pr_insts)
    scores = []
    for t in iou_thrs:
        tp, fp, fn = match_tp_fp_fn(mat, t)
        prec = tp / (tp + fp + 1e-9)
        rec  = tp / (tp + fn + 1e-9)
        scores.append(fbeta(prec, rec, beta=2.0))
    return float(np.mean(scores)) if len(scores) else 0.0

def pixel_confusion(gt: np.ndarray, pr: np.ndarray) -> Tuple[int, int, int, int]:
    gt = gt.astype(np.uint8)
    pr = pr.astype(np.uint8)
    tp = int(np.logical_and(gt == 1, pr == 1).sum())
    fp = int(np.logical_and(gt == 0, pr == 1).sum())
    fn = int(np.logical_and(gt == 1, pr == 0).sum())
    tn = int(np.logical_and(gt == 0, pr == 0).sum())
    return tp, fp, fn, tn

def pixel_metrics_from_conf(tp: int, fp: int, fn: int, tn: int) -> Dict[str, float]:
    precision = tp / (tp + fp + 1e-9)
    recall    = tp / (tp + fn + 1e-9)
    iou_      = tp / (tp + fp + fn + 1e-9)
    f2_       = fbeta(precision, recall, beta=2.0)

    total = tp + fp + fn + tn
    if total <= 0:
        kappa = 0.0
    else:
        po = (tp + tn) / total
        pe = (((tp + fp) / total) * ((tp + fn) / total) +
              ((fn + tn) / total) * ((fp + tn) / total))
        denom = (1 - pe)
        kappa = (po - pe) / denom if denom != 0 else 0.0

    return {
        "F2": float(f2_),
        "IoU": float(iou_),
        "precision": float(precision),
        "recall": float(recall),
        "kappa": float(kappa),
    }


# ---------------------------
# Dataset
# ---------------------------

IMAGENET_MEAN = (0.485, 0.456, 0.406)
IMAGENET_STD  = (0.229, 0.224, 0.225)

class ShipSegDataset(Dataset):
    def __init__(self,
                 images_dir: str,
                 masks_dir: Optional[str],
                 resize: Optional[int] = None,
                 augment: bool = False):
        self.images_dir = images_dir
        self.masks_dir = masks_dir
        self.resize = resize
        self.augment = augment

        self.image_paths = list_images(images_dir, exts=(".jpg", ".jpeg", ".png"))
        if len(self.image_paths) == 0:
            raise RuntimeError(f"No images found in {images_dir}")

        self.has_masks = masks_dir is not None and os.path.isdir(masks_dir)

    def __len__(self):
        return len(self.image_paths)

    def _read_image(self, path: str) -> Image.Image:
        return Image.open(path).convert("RGB")

    def _read_mask(self, img_path: str) -> Image.Image:
        if not self.has_masks:
            raise RuntimeError("Masks not available")
        base = os.path.basename(img_path)
        stem, _ = os.path.splitext(base)
        mask_path = os.path.join(self.masks_dir, stem + ".png")
        if not os.path.exists(mask_path):
            alt = os.path.join(self.masks_dir, stem + ".jpg")
            if os.path.exists(alt):
                mask_path = alt
            else:
                raise FileNotFoundError(f"Mask not found: {mask_path}")
        return Image.open(mask_path).convert("L")

    def _to_tensor_norm(self, img: Image.Image) -> torch.Tensor:
        arr = np.asarray(img).astype(np.float32) / 255.0
        arr = (arr - np.array(IMAGENET_MEAN, dtype=np.float32)) / np.array(IMAGENET_STD, dtype=np.float32)
        arr = np.transpose(arr, (2, 0, 1))
        return torch.from_numpy(arr).float()

    def _mask_to_tensor(self, mask: Image.Image) -> torch.Tensor:
        arr = (np.asarray(mask) > 127).astype(np.float32)
        return torch.from_numpy(arr).unsqueeze(0)

    def __getitem__(self, idx: int):
        img_path = self.image_paths[idx]
        img = self._read_image(img_path)
        orig_w, orig_h = img.size

        mask = None
        if self.has_masks:
            mask = self._read_mask(img_path)

        if self.resize is not None:
            img = img.resize((self.resize, self.resize), resample=Image.BILINEAR)
            if mask is not None:
                mask = mask.resize((self.resize, self.resize), resample=Image.NEAREST)

        if self.augment:
            if random.random() < 0.5:
                img = img.transpose(Image.FLIP_LEFT_RIGHT)
                if mask is not None:
                    mask = mask.transpose(Image.FLIP_LEFT_RIGHT)
            if random.random() < 0.5:
                img = img.transpose(Image.FLIP_TOP_BOTTOM)
                if mask is not None:
                    mask = mask.transpose(Image.FLIP_TOP_BOTTOM)

        x = self._to_tensor_norm(img)
        if mask is not None:
            y = self._mask_to_tensor(mask)
        else:
            y = torch.zeros((1, x.shape[1], x.shape[2]), dtype=torch.float32)

        image_id = os.path.basename(img_path)
        return {
            "image": x,
            "mask": y,
            "image_id": image_id,
            "orig_size": (orig_h, orig_w),
        }


# ---------------------------
# Model: HRNet backbone (features_only) + multi-scale fusion head
# ---------------------------

class HRNetSeg(nn.Module):
    def __init__(self,
                 backbone_name: str = "hrnet_w32.ms_in1k",
                 pretrained: bool = True,
                 fuse_ch: int = 64,
                 dropout: float = 0.1):
        super().__init__()
        self.backbone = timm.create_model(
            backbone_name,
            pretrained=pretrained,
            features_only=True,
            out_indices=(0, 1, 2, 3),
        )

        feat_info = self.backbone.feature_info
        # feature_infoが返す段数とforwardが返す段数がズレる場合があるため、
        # projはfeature_infoに基づいて作るが、forwardでは返ってきた分だけ使う。
        try:
            chs = feat_info.channels()
        except Exception:
            chs = [f["num_chs"] for f in feat_info]

        self.proj = nn.ModuleList([nn.Conv2d(c, fuse_ch, kernel_size=1) for c in chs])

        # ★ここが修正点：LazyConv2d で fused の入力chを自動推定
        self.fuse = nn.Sequential(
            nn.LazyConv2d(fuse_ch, kernel_size=3, padding=1, bias=False),
            nn.BatchNorm2d(fuse_ch),
            nn.ReLU(inplace=True),
            nn.Dropout2d(p=dropout),
            nn.Conv2d(fuse_ch, 1, kernel_size=1)
        )

    def forward(self, x: torch.Tensor) -> torch.Tensor:
        feats = self.backbone(x)  # list of tensors (段数はモデルにより変動し得る)
        target_h, target_w = feats[0].shape[-2], feats[0].shape[-1]

        ups = []
        for i, f in enumerate(feats):
            # projが足りない（極めて稀）場合に備えた保険
            if i >= len(self.proj):
                # ここに来る場合、feature_infoとforwardが大きく不整合。
                # 追加でLazyConv2d等を使う手もあるが、まずは例外で止める。
                raise RuntimeError(f"proj length ({len(self.proj)}) < feats length ({len(feats)})")
            p = self.proj[i](f)
            if p.shape[-2:] != (target_h, target_w):
                p = F.interpolate(p, size=(target_h, target_w), mode="bilinear", align_corners=False)
            ups.append(p)

        fused = torch.cat(ups, dim=1)
        logit = self.fuse(fused)

        if logit.shape[-2:] != x.shape[-2:]:
            logit = F.interpolate(logit, size=x.shape[-2:], mode="bilinear", align_corners=False)
        return logit


# ---------------------------
# Losses
# ---------------------------

class DiceLoss(nn.Module):
    def __init__(self, eps: float = 1e-6):
        super().__init__()
        self.eps = eps

    def forward(self, logits: torch.Tensor, targets: torch.Tensor) -> torch.Tensor:
        probs = torch.sigmoid(logits)
        num = 2 * (probs * targets).sum(dim=(2, 3))
        den = (probs + targets).sum(dim=(2, 3)) + self.eps
        dice = 1 - (num + self.eps) / den
        return dice.mean()


# ---------------------------
# Train / Eval
# ---------------------------

@dataclass
class EpochResult:
    train_loss: float
    val_loss: float
    best_prob_thr: float
    val_kaggle_mean_f2: float
    val_pixel: Dict[str, float]

def train_one_epoch(model, loader, optimizer, scaler, device, use_amp: bool,
                    bce_loss: nn.Module, dice_loss: nn.Module, logger: logging.Logger,
                    epoch: int, epochs: int) -> float:
    model.train()
    total_loss = 0.0
    n = 0

    for it, batch in enumerate(loader, start=1):
        x = batch["image"].to(device, non_blocking=True)
        y = batch["mask"].to(device, non_blocking=True)

        optimizer.zero_grad(set_to_none=True)

        if use_amp:
            if AMP_NEW:
                with amp_autocast(device_type="cuda"):
                    logits = model(x)
                    loss = bce_loss(logits, y) + dice_loss(logits, y)
            else:
                with amp_autocast():
                    logits = model(x)
                    loss = bce_loss(logits, y) + dice_loss(logits, y)

            scaler.scale(loss).backward()
            scaler.step(optimizer)
            scaler.update()
        else:
            logits = model(x)
            loss = bce_loss(logits, y) + dice_loss(logits, y)
            loss.backward()
            optimizer.step()

        total_loss += float(loss.item()) * x.size(0)
        n += x.size(0)

        if it == 1 or it % 200 == 0 or it == len(loader):
            logger.info(f"[Train] Ep{epoch:03d}/{epochs:03d} Iter {it:05d}/{len(loader):05d} loss={loss.item():.4f}")

    return total_loss / max(n, 1)

@torch.no_grad()
def eval_and_tune_threshold(model, loader, device, use_amp: bool,
                            bce_loss: nn.Module, dice_loss: nn.Module,
                            prob_thrs: List[float], iou_thrs: List[float],
                            tune_max_images: int, min_area: int,
                            logger: logging.Logger) -> Tuple[float, float, float, Dict[str, float]]:
    model.eval()

    thr_sum_f2 = {t: 0.0 for t in prob_thrs}
    thr_conf = {t: {"tp": 0, "fp": 0, "fn": 0, "tn": 0} for t in prob_thrs}

    total_loss = 0.0
    n = 0
    seen = 0

    for batch in loader:
        x = batch["image"].to(device, non_blocking=True)
        y = batch["mask"].to(device, non_blocking=True)

        if use_amp:
            if AMP_NEW:
                with amp_autocast(device_type="cuda"):
                    logits = model(x)
                    loss = bce_loss(logits, y) + dice_loss(logits, y)
            else:
                with amp_autocast():
                    logits = model(x)
                    loss = bce_loss(logits, y) + dice_loss(logits, y)
        else:
            logits = model(x)
            loss = bce_loss(logits, y) + dice_loss(logits, y)

        total_loss += float(loss.item()) * x.size(0)
        n += x.size(0)

        probs = torch.sigmoid(logits).detach().cpu().numpy()
        gts = y.detach().cpu().numpy()

        B = probs.shape[0]
        for i in range(B):
            if tune_max_images > 0 and seen >= tune_max_images:
                break
            pr_prob = probs[i, 0]
            gt_bin = (gts[i, 0] > 0.5).astype(np.uint8)

            for thr in prob_thrs:
                pr_bin = (pr_prob >= thr).astype(np.uint8)

                tp, fp, fn, tn = pixel_confusion(gt_bin, pr_bin)
                thr_conf[thr]["tp"] += tp
                thr_conf[thr]["fp"] += fp
                thr_conf[thr]["fn"] += fn
                thr_conf[thr]["tn"] += tn

                f2_img = kaggle_mean_f2_for_image(gt_bin, pr_bin, iou_thrs=iou_thrs, min_area=min_area)
                thr_sum_f2[thr] += f2_img

            seen += 1

        if tune_max_images > 0 and seen >= tune_max_images:
            break

    val_loss = total_loss / max(n, 1)
    denom = max(seen, 1)

    thr_mean_f2 = {t: thr_sum_f2[t] / denom for t in prob_thrs}
    thr_pix = {t: pixel_metrics_from_conf(**thr_conf[t]) for t in prob_thrs}

    best_thr = prob_thrs[0]
    best_f2 = thr_mean_f2[best_thr]
    best_iou = thr_pix[best_thr]["IoU"]
    for t in prob_thrs[1:]:
        f2v = thr_mean_f2[t]
        iouv = thr_pix[t]["IoU"]
        if (f2v > best_f2) or (abs(f2v - best_f2) < 1e-12 and iouv > best_iou):
            best_thr = t
            best_f2 = f2v
            best_iou = iouv

    return val_loss, float(best_thr), float(best_f2), thr_pix[best_thr]

@torch.no_grad()
def eval_fixed_threshold(model, loader, device, use_amp: bool,
                         prob_thr: float, iou_thrs: List[float],
                         min_area: int) -> Tuple[float, Dict[str, float]]:
    model.eval()
    sum_f2 = 0.0
    tp = fp = fn = tn = 0
    n = 0

    for batch in loader:
        x = batch["image"].to(device, non_blocking=True)
        y = batch["mask"].to(device, non_blocking=True)

        if use_amp:
            if AMP_NEW:
                with amp_autocast(device_type="cuda"):
                    logits = model(x)
            else:
                with amp_autocast():
                    logits = model(x)
        else:
            logits = model(x)

        probs = torch.sigmoid(logits).detach().cpu().numpy()
        gts = y.detach().cpu().numpy()
        B = probs.shape[0]
        for i in range(B):
            pr_prob = probs[i, 0]
            gt_bin = (gts[i, 0] > 0.5).astype(np.uint8)
            pr_bin = (pr_prob >= prob_thr).astype(np.uint8)

            sum_f2 += kaggle_mean_f2_for_image(gt_bin, pr_bin, iou_thrs=iou_thrs, min_area=min_area)
            tpi, fpi, fni, tni = pixel_confusion(gt_bin, pr_bin)
            tp += tpi; fp += fpi; fn += fni; tn += tni
            n += 1

    kaggle_mean_f2 = sum_f2 / max(n, 1)
    pix = pixel_metrics_from_conf(tp, fp, fn, tn)
    return float(kaggle_mean_f2), pix


# ---------------------------
# Submission generation (Kaggle official test)
# ---------------------------

def find_kaggle_test_dir(kaggle_test_dir: Optional[str], kaggle_root: Optional[str]) -> Optional[str]:
    candidates = []
    if kaggle_test_dir is not None and os.path.isdir(kaggle_test_dir):
        return kaggle_test_dir

    if kaggle_root is not None and os.path.isdir(kaggle_root):
        for name in ["test_v2", "test", "test_images", "images_test", "test_v2_full"]:
            p = os.path.join(kaggle_root, name)
            if os.path.isdir(p):
                candidates.append(p)

        subs = [os.path.join(kaggle_root, d) for d in os.listdir(kaggle_root)]
        subs = [d for d in subs if os.path.isdir(d)]
        for d in subs:
            jpgs = glob.glob(os.path.join(d, "*.jpg"))
            if len(jpgs) > 1000:
                candidates.append(d)

    candidates = sorted(list(set(candidates)))
    for c in candidates:
        if len(glob.glob(os.path.join(c, "*.jpg"))) > 0:
            return c
    return None

@torch.no_grad()
def generate_submission_csv(model, test_images_dir: str, device, use_amp: bool,
                            prob_thr: float, resize: Optional[int],
                            min_area: int, batch_size: int, num_workers: int,
                            out_csv_path: str, logger: logging.Logger):
    model.eval()
    ds = ShipSegDataset(test_images_dir, masks_dir=None, resize=resize, augment=False)
    loader = DataLoader(ds, batch_size=batch_size, shuffle=False,
                        num_workers=num_workers, pin_memory=True)

    rows = []
    processed = 0

    for batch in loader:
        x = batch["image"].to(device, non_blocking=True)
        image_ids = batch["image_id"]
        orig_sizes = batch["orig_size"]

        if use_amp:
            if AMP_NEW:
                with amp_autocast(device_type="cuda"):
                    logits = model(x)
            else:
                with amp_autocast():
                    logits = model(x)
        else:
            logits = model(x)

        probs = torch.sigmoid(logits).detach().cpu().numpy()

        B = probs.shape[0]
        for i in range(B):
            image_id = image_ids[i]
            pr_prob = probs[i, 0]
            pr_bin = (pr_prob >= prob_thr).astype(np.uint8)

            orig_h, orig_w = orig_sizes[i]
            if resize is not None:
                pr_img = Image.fromarray((pr_bin * 255).astype(np.uint8), mode="L")
                pr_img = pr_img.resize((orig_w, orig_h), resample=Image.NEAREST)
                pr_bin_full = (np.asarray(pr_img) > 127).astype(np.uint8)
            else:
                pr_bin_full = pr_bin

            insts = mask_to_instances(pr_bin_full, min_area=min_area)

            if len(insts) == 0:
                rows.append((image_id, ""))
            else:
                for inst in insts:
                    rle = rle_encode(inst)
                    rows.append((image_id, rle))

            processed += 1
            if processed % 2000 == 0:
                logger.info(f"[Submission] processed {processed}/{len(ds)} images...")

    ensure_dir(os.path.dirname(out_csv_path))
    with open(out_csv_path, "w", encoding="utf-8") as f:
        f.write("ImageId,EncodedPixels\n")
        for image_id, enc in rows:
            f.write(f"{image_id},{enc}\n")

    logger.info(f"[SUBMISSION] saved -> {out_csv_path} (rows={len(rows)})")


# ---------------------------
# Main
# ---------------------------

def parse_args():
    p = argparse.ArgumentParser("HRNetV2 baseline: full-train + local eval + kaggle submission")

    p.add_argument("--split-dir", type=str, default=
                   "/home/ougaishibashi/kaggle_competition/airbus-ship-detection/prepared_splits/"
                   "SCALE_100PCT__TRAIN70_VAL15_TEST15__SEED42")
    p.add_argument("--save-dir", type=str, default=None,
                   help="Where to save logs/checkpoints. default: same as split-dir")

    p.add_argument("--kaggle-test-dir", type=str, default=None,
                   help="Path to Kaggle official test images (e.g., test_v2). If None, try auto-detect.")
    p.add_argument("--kaggle-root", type=str, default="/home/ougaishibashi/kaggle_competition/airbus-ship-detection",
                   help="Root folder to auto-detect test_v2 if --kaggle-test-dir not set.")

    p.add_argument("--backbone", type=str, default="hrnet_w32.ms_in1k")
    p.add_argument("--no-pretrained", action="store_true")
    p.add_argument("--fuse-ch", type=int, default=64)
    p.add_argument("--dropout", type=float, default=0.1)

    p.add_argument("--epochs", type=int, default=30)
    p.add_argument("--batch-size", type=int, default=8)
    p.add_argument("--lr", type=float, default=1e-4)
    p.add_argument("--weight-decay", type=float, default=1e-4)
    p.add_argument("--num-workers", type=int, default=4)
    p.add_argument("--amp", action="store_true")

    p.add_argument("--resize", type=int, default=None, help="Optional square resize (e.g., 512). default None")

    p.add_argument("--prob-thrs", type=str, default="0.05,0.1,0.15,0.2,0.25,0.3,0.35,0.4,0.45,0.5,0.55,0.6,0.65,0.7,0.75,0.8,0.85,0.9,0.95")
    p.add_argument("--iou-thrs", type=str, default="0.5,0.55,0.6,0.65,0.7,0.75,0.8,0.85,0.9,0.95")
    p.add_argument("--tune-max-images", type=int, default=2000,
                   help="0=all (very heavy on full val). recommended 2000-5000 for speed.")
    p.add_argument("--min-area", type=int, default=0, help="Remove predicted instances smaller than this area.")

    p.add_argument("--pos-weight", type=float, default=None,
                   help="BCE pos_weight. If None, no weighting. (You can set e.g., 10.0)")

    p.add_argument("--seed", type=int, default=42)
    p.add_argument("--deterministic", action="store_true")

    p.add_argument("--resume", type=str, default=None, help="Path to checkpoint to resume")

    return p.parse_args()


def main():
    args = parse_args()

    split_dir = args.split_dir
    save_dir = args.save_dir if args.save_dir is not None else split_dir
    ensure_dir(save_dir)

    run_name = f"RUN__{now_str()}__{os.path.basename(split_dir)}"
    log_path = os.path.join(save_dir, "logs", f"{run_name}.log")
    logger = setup_logger(log_path)

    device = "cuda" if torch.cuda.is_available() else "cpu"
    use_amp = bool(args.amp and device == "cuda")

    prob_thrs = [float(x) for x in args.prob_thrs.split(",")]
    iou_thrs  = [float(x) for x in args.iou_thrs.split(",")]

    set_seed(args.seed, deterministic=args.deterministic)

    train_images = os.path.join(split_dir, "train_images")
    train_masks  = os.path.join(split_dir, "train_masks")
    val_images   = os.path.join(split_dir, "val_images")
    val_masks    = os.path.join(split_dir, "val_masks")
    test_images  = os.path.join(split_dir, "test_images")
    test_masks   = os.path.join(split_dir, "test_masks")

    if not os.path.isdir(train_images) or not os.path.isdir(train_masks):
        raise RuntimeError(f"Invalid split-dir. train_images/train_masks not found in: {split_dir}")

    ds_train = ShipSegDataset(train_images, train_masks, resize=args.resize, augment=True)
    ds_val   = ShipSegDataset(val_images, val_masks, resize=args.resize, augment=False)

    test_has_masks = os.path.isdir(test_masks)
    ds_test  = ShipSegDataset(test_images, test_masks if test_has_masks else None,
                              resize=args.resize, augment=False)

    dl_train = DataLoader(ds_train, batch_size=args.batch_size, shuffle=True,
                          num_workers=args.num_workers, pin_memory=True, drop_last=False)
    dl_val   = DataLoader(ds_val, batch_size=args.batch_size, shuffle=False,
                          num_workers=args.num_workers, pin_memory=True, drop_last=False)
    dl_test  = DataLoader(ds_test, batch_size=args.batch_size, shuffle=False,
                          num_workers=args.num_workers, pin_memory=True, drop_last=False)

    model = HRNetSeg(
        backbone_name=args.backbone,
        pretrained=(not args.no_pretrained),
        fuse_ch=args.fuse_ch,
        dropout=args.dropout,
    ).to(device)

    # ★LazyConv2dの初期化を確実にするため、optimizer作成前にダミーforward
    dummy_hw = args.resize if args.resize is not None else 768  # Airbusは通常 768x768
    with torch.no_grad():
        dummy = torch.zeros(1, 3, dummy_hw, dummy_hw, device=device)
        _ = model(dummy)

    if args.pos_weight is not None:
        pos_weight_tensor = torch.tensor([args.pos_weight], dtype=torch.float32, device=device)
        bce_loss = nn.BCEWithLogitsLoss(pos_weight=pos_weight_tensor)
    else:
        bce_loss = nn.BCEWithLogitsLoss()
    dice_loss = DiceLoss()

    optimizer = torch.optim.AdamW(model.parameters(), lr=args.lr, weight_decay=args.weight_decay)
    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=args.epochs)

    scaler = AmpGradScaler("cuda") if (use_amp and AMP_NEW) else (AmpGradScaler() if use_amp else None)

    start_epoch = 1
    best_val_f2 = -1.0
    best_thr = prob_thrs[-1]
    ckpt_dir = os.path.join(save_dir, "checkpoints")
    ensure_dir(ckpt_dir)
    best_path = os.path.join(save_dir, "BEST__hrnetv2_baseline.pth")
    best_thr_path = os.path.join(save_dir, "BEST__prob_threshold.json")

    if args.resume is not None and os.path.isfile(args.resume):
        ckpt = torch.load(args.resume, map_location="cpu")
        model.load_state_dict(ckpt["model"], strict=True)
        optimizer.load_state_dict(ckpt["optim"])
        scheduler.load_state_dict(ckpt["sched"])
        if scaler is not None and "scaler" in ckpt and ckpt["scaler"] is not None:
            scaler.load_state_dict(ckpt["scaler"])
        start_epoch = int(ckpt.get("epoch", 0)) + 1
        best_val_f2 = float(ckpt.get("best_val_f2", best_val_f2))
        best_thr = float(ckpt.get("best_thr", best_thr))
        logger.info(f"[Resume] from {args.resume} -> start_epoch={start_epoch}, best_val_f2={best_val_f2:.4f}, best_thr={best_thr:.2f}")

    logger.info("=== CONFIG ===")
    logger.info(f"split_dir      = {split_dir}")
    logger.info(f"save_dir       = {save_dir}")
    logger.info(f"log_path       = {log_path}")
    logger.info(f"device         = {device} | amp={use_amp}")
    logger.info(f"backbone       = {args.backbone} | pretrained={not args.no_pretrained}")
    logger.info(f"fuse_ch        = {args.fuse_ch} | dropout={args.dropout}")
    logger.info(f"epochs         = {args.epochs} | batch_size={args.batch_size}")
    logger.info(f"lr             = {args.lr} | weight_decay={args.weight_decay}")
    logger.info(f"resize         = {args.resize}")
    logger.info(f"seed           = {args.seed} | deterministic={args.deterministic}")
    logger.info(f"min_area       = {args.min_area}")
    logger.info(f"pos_weight     = {args.pos_weight}")
    logger.info(f"prob_thrs      = {prob_thrs}")
    logger.info(f"iou_thrs       = {iou_thrs}")
    logger.info(f"tune_max_images= {args.tune_max_images} (0=all)")
    logger.info(f"n_train={len(ds_train)} n_val={len(ds_val)} n_test={len(ds_test)} test_has_masks={test_has_masks}")
    logger.info("==============")

    logger.info("=== TRAIN START ===")
    for ep in range(start_epoch, args.epochs + 1):
        t_ep0 = time.time()
        train_loss = train_one_epoch(
            model, dl_train, optimizer, scaler, device, use_amp,
            bce_loss, dice_loss, logger, ep, args.epochs
        )

        val_loss, tuned_thr, val_kaggle_f2, val_pixel = eval_and_tune_threshold(
            model, dl_val, device, use_amp,
            bce_loss, dice_loss,
            prob_thrs=prob_thrs, iou_thrs=iou_thrs,
            tune_max_images=args.tune_max_images,
            min_area=args.min_area,
            logger=logger
        )

        scheduler.step()

        elapsed = time.time() - t_ep0
        logger.info(
            f"[Epoch {ep:03d}/{args.epochs:03d}] time={elapsed:.1f}s "
            f"train_loss={train_loss:.4f} val_loss={val_loss:.4f} "
            f"VAL KaggleMeanF2={val_kaggle_f2:.4f} (prob_thr={tuned_thr:.2f}, tuned_on={args.tune_max_images if args.tune_max_images>0 else len(ds_val)}) | "
            f"pixel(F2={val_pixel['F2']:.4f}, IoU={val_pixel['IoU']:.4f}, P={val_pixel['precision']:.4f}, R={val_pixel['recall']:.4f}, Kappa={val_pixel['kappa']:.4f})"
        )

        ckpt_path = os.path.join(ckpt_dir, f"ckpt_ep{ep:03d}.pth")
        torch.save({
            "epoch": ep,
            "model": model.state_dict(),
            "optim": optimizer.state_dict(),
            "sched": scheduler.state_dict(),
            "scaler": (scaler.state_dict() if scaler is not None else None),
            "best_val_f2": best_val_f2,
            "best_thr": best_thr,
            "args": vars(args),
        }, ckpt_path)

        if val_kaggle_f2 > best_val_f2:
            best_val_f2 = val_kaggle_f2
            best_thr = tuned_thr
            torch.save(model.state_dict(), best_path)
            save_json(best_thr_path, {"prob_thr": best_thr, "best_val_kaggle_mean_f2": best_val_f2, "epoch": ep})
            logger.info(f"[BEST UPDATE] epoch={ep} val_kaggle_mean_f2={best_val_f2:.4f} prob_thr={best_thr:.2f} | saved: {os.path.basename(best_path)}, {os.path.basename(best_thr_path)}")

    logger.info("=== TRAIN DONE ===")
    logger.info(f"BEST val_kaggle_mean_f2={best_val_f2:.4f} best_prob_thr={best_thr:.2f}")
    logger.info("=== FINAL EVAL (load best) ===")

    if os.path.isfile(best_path):
        model.load_state_dict(torch.load(best_path, map_location="cpu"), strict=True)
    else:
        logger.info("[WARN] BEST weight not found; using last epoch weights.")

    val_f2, val_pix = eval_fixed_threshold(model, dl_val, device, use_amp,
                                           prob_thr=best_thr, iou_thrs=iou_thrs, min_area=args.min_area)
    logger.info(f"[VAL ] KaggleMeanF2={val_f2:.4f} | pixel(F2={val_pix['F2']:.4f}, IoU={val_pix['IoU']:.4f}, P={val_pix['precision']:.4f}, R={val_pix['recall']:.4f}, Kappa={val_pix['kappa']:.4f})")

    if test_has_masks:
        test_f2, test_pix = eval_fixed_threshold(model, dl_test, device, use_amp,
                                                 prob_thr=best_thr, iou_thrs=iou_thrs, min_area=args.min_area)
        logger.info(f"[TEST] KaggleMeanF2={test_f2:.4f} | pixel(F2={test_pix['F2']:.4f}, IoU={test_pix['IoU']:.4f}, P={test_pix['precision']:.4f}, R={test_pix['recall']:.4f}, Kappa={test_pix['kappa']:.4f})")
    else:
        test_f2, test_pix = None, None
        logger.info("[TEST] test_masks not found -> skip local test evaluation")

    report = {
        "split_dir": split_dir,
        "save_dir": save_dir,
        "best": {
            "best_val_kaggle_mean_f2": best_val_f2,
            "best_prob_thr": best_thr,
        },
        "val": {
            "kaggle_mean_f2": val_f2,
            "pixel": val_pix,
        },
        "test": {
            "has_masks": bool(test_has_masks),
            "kaggle_mean_f2": test_f2,
            "pixel": test_pix,
        }
    }
    report_path = os.path.join(save_dir, "REPORT__val_test_metrics.json")
    save_json(report_path, report)
    logger.info(f"[REPORT] saved -> {report_path}")

    logger.info("=== SUBMISSION GENERATION ===")
    official_test_dir = find_kaggle_test_dir(args.kaggle_test_dir, args.kaggle_root)
    if official_test_dir is None:
        logger.info("[WARN] Kaggle official test dir not found. Set --kaggle-test-dir explicitly to generate submission.")
        logger.info("=== DONE ===")
        return

    sub_path = os.path.join(
        save_dir,
        f"SUBMISSION__HRNetV2_BASELINE__{os.path.basename(split_dir)}.csv"
    )
    generate_submission_csv(
        model=model,
        test_images_dir=official_test_dir,
        device=device,
        use_amp=use_amp,
        prob_thr=best_thr,
        resize=args.resize,
        min_area=args.min_area,
        batch_size=args.batch_size,
        num_workers=args.num_workers,
        out_csv_path=sub_path,
        logger=logger
    )

    logger.info("=== DONE ===")


if __name__ == "__main__":
    main()

